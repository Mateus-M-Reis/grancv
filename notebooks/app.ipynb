{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import ipywidgets as wid\n",
    "import random\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as mplstyle\n",
    "from matplotlib.pyplot import figure, draw, pause\n",
    "\n",
    "import bqplot.pyplot as bplt\n",
    "import bqplot as bq\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "import cv2\n",
    "\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "#from skimage.morphology import watershed\n",
    "#from skimage.feature import peak_local_max\n",
    "#from sklearn.feature_extraction import image\n",
    "#from sklearn.cluster import spectral_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f7c797ae710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize']=[30, 20]\n",
    "plt.rcParams[\"image.aspect\"] = 'equal' \n",
    "#plt.gray()\n",
    "plt.style.use('dark_background')\n",
    "mplstyle.use('fast')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "document.body.classList.add('theme-dark')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "document.body.classList.add('theme-dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_path = os.path.abspath('./imagens/input/granulometry/desmonte.jpg')\n",
    "#file = open(\"/root/MEGA/Códigos/cvgran/input/granulometry/desmonte.jpg\", \"rb\")\n",
    "#image = file.read()\n",
    "\n",
    "img = cv2.imread('../input/images/desmonte.jpg',1)\n",
    "#print(img.shape)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#print(img_rgb.shape)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_layout = wid.Layout(display='flex',\n",
    "                        flex_flow='column',  \n",
    "                        align_items='stretch')\n",
    "\n",
    "out_test = wid.Layout(flex_flow ='row wrap', border = '0px solid white', display='flex',\n",
    "                      min_width='800px', max_width='1000px', \n",
    "                      min_height='400px', max_height='800px',\n",
    "                      align_items='center',justify_content='center',\n",
    "                      overflow_x='auto', overflow_y='auto'\n",
    "                     )\n",
    "\n",
    "ac_layout = wid.Layout(display='flex',\n",
    "                             flex_flow='column',  \n",
    "                             align_items='stretch',\n",
    "                             width='430px')\n",
    "\n",
    "ac_items_layout = wid.Layout(display='flex',\n",
    "                             flex_flow='column',  \n",
    "                             align_items='stretch',\n",
    "                             width='410px')\n",
    "#################################################################################################################\n",
    "header        = wid.HTML(value=\"<h1>Análise de Imagens</h1>\")\n",
    "\n",
    "data_buttom = wid.FileUpload(accept='*.jpeg *.jpg *.png',\n",
    "                             multiple=False\n",
    "                            )\n",
    "#################################################################################################################\n",
    "simple_thresh_drop=wid.Dropdown(options=['THRESH_BINARY','THRESH_BINARY_INV','THRESH_TRUNC','THRESH_TOZERO','THRESH_TOZERO_INV'],\n",
    "                                value='THRESH_BINARY',\n",
    "                                description='Method',\n",
    "                                style={'description_width':'44px'},\n",
    "                                disabled=False\n",
    "                               )\n",
    "simple_thresh_slider=wid.IntSlider(value=127, min=0, max=255, step=1, description='Thresh Value:',\n",
    "                                  layout={'max_width':'440px', 'width':'auto'}\n",
    "                                  )\n",
    "simple_items = wid.Box([simple_thresh_drop,\n",
    "                        simple_thresh_slider ],\n",
    "                       layout=ac_items_layout\n",
    "                      )\n",
    "############################################################################\n",
    "adapta_thresh_drop=wid.Dropdown(options=['ADAPTIVE_THRESH_MEAN_C', 'ADAPTIVE_THRESH_GAUSSIAN_C'],\n",
    "                                value='ADAPTIVE_THRESH_MEAN_C',\n",
    "                                description='Method',\n",
    "                                style={'description_width':'44px'},\n",
    "                                disabled=False\n",
    "                               )\n",
    "adapta_block_size=wid.IntSlider(value=11, min=3, max=21, step=2, description='Block Size',\n",
    "                                  layout={'max_width':'440px', 'width':'auto'}\n",
    "                               )\n",
    "adapta_block_C=wid.IntSlider(value=7, min=-21, max=21, step=1, description='C',\n",
    "                                  layout={'max_width':'440px', 'width':'auto'}\n",
    "                            )\n",
    "adapta_items = wid.Box([adapta_thresh_drop, \n",
    "                        wid.Box([adapta_block_size,\n",
    "                                 adapta_block_C],\n",
    "                                layout=ac_items_layout)],\n",
    "                       layout=ac_items_layout\n",
    "                      ) \n",
    "############################################################################\n",
    "morpho_drop = wid.Dropdown(options=['Erosion', 'Dilation', 'Opening', 'Closing','Morphological Gradient',\n",
    "                                   'Top Hat', 'Black Hat'],\n",
    "                           value='Erosion', description='Operação Morphológica',disabled=False)\n",
    "morpho_iter_s = wid.IntSlider(min=0, max=10, step=1, description='Iteration Value',\n",
    "                                  layout={'max_width':'440px', 'width':'auto'})\n",
    "\n",
    "morpho_items = wid.Box([morpho_drop, morpho_iter_s],\n",
    "                       layout=ac_items_layout)\n",
    "############################################################################\n",
    "ws_op_iter = wid.IntSlider(min=0, max=6, value=2, step=1, description='Opening Iterations Number', layout={'max_width':'440px', 'width':'auto'})\n",
    "ws_bg_iter = wid.IntSlider(min=0, max=6, value=3, step=1, description='Dilate Iterations Number', layout={'max_width':'440px', 'width':'auto'})\n",
    "ws_sf_tfactor = wid.FloatSlider(min=0.1, max=0.9, value=0.7, step=0.1, description='Sure Figure Threshold Factor', layout={'max_width':'440px', 'width':'auto'})\n",
    "ws_sf_tvalue = wid.IntSlider(min=0, max=255, value=1, step=1, description='Sure Figure Threshold Factor', layout={'max_width':'440px', 'width':'auto'})\n",
    "\n",
    "\n",
    "ws_items = wid.Box([ws_op_iter, ws_bg_iter, ws_sf_tfactor, ws_sf_tvalue],\n",
    "                   layout=ac_items_layout)\n",
    "############################################################################\n",
    "c_t1 = wid.IntSlider(min=0, max=255, value=100, step=1, description='Threshold 1 Value', layout={'max_width':'440px', 'width':'auto'})\n",
    "c_t2 = wid.IntSlider(min=0, max=255, value=200, step=1, description='Threshold 2 Value', layout={'max_width':'440px', 'width':'auto'})\n",
    "\n",
    "c_items = wid.Box([c_t1, c_t2], layout=ac_items_layout)\n",
    "############################################################################\n",
    "contour_t_value = wid.IntSlider(min=0, max=255, value=127, description='Threshold Value', layout={'max_width':'440px', 'width':'auto'})\n",
    "#contour_t_type = wid.IntSlider(min=0, max=7, value=0, description='Threshold Type', layout={'max_width':'440px', 'width':'auto'})\n",
    "im_seg_cont_title  = wid.HTML(value='<h4>Achando Contornos')\n",
    "\n",
    "im_seg_c_conv  = wid.HTML(value='<h4>Casco Convexo')\n",
    "im_seg_h_t = wid.IntSlider(min=0, max=255, value=127, description='Threshold Value', \n",
    "                           layout={'max_width':'440px', 'width':'auto'})\n",
    "\n",
    "im_seg_a_elip  = wid.HTML(value='<h4>Ajuste de Elipses')\n",
    "im_seg_e_t = wid.IntSlider(min=0, max=255, value=127, description='Threshold Value', \n",
    "                           layout={'max_width':'440px', 'width':'auto'})\n",
    "\n",
    "contour_items=wid.Box([im_seg_cont_title,\n",
    "         contour_t_value,\n",
    "         im_seg_c_conv,\n",
    "         im_seg_h_t,\n",
    "         im_seg_a_elip,\n",
    "                      im_seg_e_t],\n",
    "        layout=ac_items_layout)\n",
    "############################################################################\n",
    "p_f_title = wid.HTML(value='<h4> Image Filtering')\n",
    "p_f_ksize = wid.IntSlider(min=3, max=9, step=2)\n",
    "\n",
    "p_a_title = wid.HTML(value='<h4> Averaging ')\n",
    "p_a_ksize = wid.IntSlider(min=3, max=9, step=2)\n",
    "\n",
    "p_g_title = wid.HTML(value='<h4> Filtro Gaussiano ')\n",
    "p_g_ksize = wid.IntSlider(min=3, max=9, step=2)\n",
    "\n",
    "p_m_title = wid.HTML(value='<h4> Filtragem Mediana ')\n",
    "p_m_ksize = wid.IntSlider(min=3, max=9, step=2)\n",
    "\n",
    "p_b_title = wid.HTML(value='<h4> Filtragem Bilateral ')\n",
    "p_b_d = wid.IntSlider(min=3, max=9, value=5, step=2)\n",
    "p_b_s1 = wid.IntSlider(min=5, max=185, step=1)\n",
    "\n",
    "pre_items = wid.Box([p_f_title, p_f_ksize, \n",
    "                     p_a_title,p_a_ksize, \n",
    "                     p_g_title,p_g_ksize, \n",
    "                     p_m_title, p_m_ksize,\n",
    "                     p_b_title,p_b_d, p_b_s1],\n",
    "                       layout=out_layout\n",
    "                      )\n",
    "############################################################################\n",
    "left_accordion = wid.Accordion(children=[pre_items,\n",
    "                                         morpho_items,\n",
    "                                         simple_items,\n",
    "                                         adapta_items,\n",
    "                                         ws_items,\n",
    "                                         c_items,\n",
    "                                         contour_items\n",
    "                                        ],\n",
    "                               layout=ac_layout\n",
    "                              )\n",
    "left_accordion.set_title(0,'Pré-Processamento')\n",
    "left_accordion.set_title(1,'Morphological Operations')\n",
    "left_accordion.set_title(2,'Thresholding Simples')\n",
    "left_accordion.set_title(3,'Thresholding Adaptivo')\n",
    "left_accordion.set_title(4,'Watershed')\n",
    "left_accordion.set_title(5,'Canny Edge Detection')\n",
    "left_accordion.set_title(6,'Segmentação de Imagens')\n",
    "\n",
    "#options = wid.Tab(children=[left_accordion], layout =  wid.Layout(display='flex',flex_flow='column',  \n",
    " #                                                       align_items='stretch', width='460px')\n",
    "  #     )\n",
    "options = left_accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0954403f0fb74ea887f44addeb31e838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Output(layout=Layout(grid_area='header', height='120px')), Output(layout=Layout(grid_area=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_left = wid.Output()\n",
    "with out_left:\n",
    "    display(options)\n",
    "\n",
    "############################################################################\n",
    "\n",
    "out_center = wid.Output(layout=out_test)\n",
    "\n",
    "############################################################################\n",
    "out_top = wid.Output(layout=wid.Layout(height='120px'))\n",
    "############################################################################\n",
    "out_right=wid.Output()\n",
    "\n",
    "############################################################################\n",
    "out_bottom = wid.Output()\n",
    "############################################################################\n",
    "app = wid.AppLayout(header=out_top,\n",
    "          left_sidebar=out_left,\n",
    "          center=out_center,\n",
    "          right_sidebar=out_right,\n",
    "          footer=out_bottom)\n",
    "#################################################################################################################\n",
    "#fg = figure()\n",
    "scale=1.0\n",
    "canvas = Canvas(size=(scale*img.shape[1], scale*img.shape[0]))\n",
    "canvas.put_image_data(img, 0, 0)\n",
    "\n",
    "with app.center:\n",
    "    #display(plt.imshow(img_gray))\n",
    "    #display(Image(filename='./imagens/desmonte.jpg'))\n",
    "    display(canvas)\n",
    "############################################################################\n",
    "with app.header:\n",
    "    display(header, data_buttom)\n",
    "############################################################################   \n",
    "sv_state_b = wid.Button(description='Salvar Estado', \n",
    "                       tooltip='Esta será a Imagem Utilizada nas Próximas Etapas')\n",
    "\n",
    "sv_img_b = wid.Button(description='Salvar Imagem', \n",
    "                          tooltip='Salvar no Arquivo')\n",
    "\n",
    "ax_options={'x': dict(label='Size (mm)', grid_lines='solid', orientation='horizontal'), \n",
    "            'y': dict(label='Porcentagem Passante Acumulada', grid_lines='solid', orientation='vertical', \n",
    "                      tick_format='0.2f')}\n",
    "xs = bq.LinearScale(min=0, max=256)\n",
    "ys = bq.LinearScale(min=0)\n",
    "\n",
    "with app.right_sidebar:\n",
    "    display(wid.HBox([sv_state_b, sv_img_b]))\n",
    "    \n",
    "with app.right_sidebar:\n",
    "    bq_hist_fig = bplt.figure(title='Frequência', title_style={'font-size': '20px'}, \n",
    "                              animation_duration=1000, axes_options=ax_options,\n",
    "                              layout={'height':'550px', 'width':'550px'},\n",
    "                              fig_margin={'top':0,'bottom':30, 'left':50, 'right':30},\n",
    "                              scale_x=xs, scale_y=ys\n",
    "                             )\n",
    "    hist_data = cv2.calcHist([img_gray],[0],None,[256],[0,256])\n",
    "    hist = bplt.plot(x=range(0,256), y=hist_data,\n",
    "                     colors=['white'], fill='bottom', fill_opacities=[0.5], stroke_width=1.0)\n",
    "    bplt.show()\n",
    "    #display(bq_hist_fig)\n",
    "#################################################################################################################\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprossessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def p_f(k_size, img=img):\n",
    "    kernel = np.ones((k_size,k_size),np.float32)/25\n",
    "    dst = cv2.filter2D(img,-1,kernel)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(dst, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([dst],[0],None,[256],[0,256])\n",
    "out_center=wid.interactive_output(p_f, {'k_size':p_f_ksize})\n",
    "\n",
    "def p_a(k_size, img=img):\n",
    "    blur = cv2.blur(img,(k_size,k_size))\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(blur, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([blur],[0],None,[256],[0,256])\n",
    "out_center=wid.interactive_output(p_a, {'k_size':p_a_ksize})\n",
    "\n",
    "def p_g(k_size, img=img):\n",
    "    blur = cv2.GaussianBlur(img,(k_size,k_size),0)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(blur, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([blur],[0],None,[256],[0,256])\n",
    "out_center=wid.interactive_output(p_g, {'k_size':p_g_ksize})\n",
    "\n",
    "def p_m(k_size, img=img):\n",
    "    median = cv2.medianBlur(img,k_size)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(median, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([median],[0],None,[256],[0,256])\n",
    "out_center=wid.interactive_output(p_m, {'k_size':p_m_ksize})\n",
    "\n",
    "def p_b(d, sigma1, img=img):\n",
    "    blur = cv2.bilateralFilter(img,d,sigma1,sigma1)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(blur, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([blur],[0],None,[256],[0,256])\n",
    "out_center=wid.interactive_output(p_b, {'d':p_b_d,\n",
    "                                       'sigma1':p_b_s1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformações Morfológicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def morpho(iterate, img=img):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    if morpho_drop.value=='Erosion':\n",
    "        morpho_img = cv2.erode(img, kernel, iterations=iterate)\n",
    "    elif morpho_drop.value=='Dilation':\n",
    "        morpho_img = cv2.dilate(img, kernel, iterations=iterate)\n",
    "    elif morpho_drop.value=='Opening':\n",
    "        morpho_img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=iterate)\n",
    "    elif morpho_drop.value=='Closing':\n",
    "        morpho_img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=iterate)\n",
    "    elif morpho_drop.value=='Morphological Gradient':\n",
    "        morpho_img = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel, iterations=iterate)\n",
    "    elif morpho_drop.value=='Top Hat':\n",
    "        morpho_img = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel, iterations=iterate)\n",
    "    elif morpho_drop.value=='Black Hat':\n",
    "        morpho_img = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel, iterations=iterate)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(morpho_img, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([morpho_img],[0],None,[256],[0,256])\n",
    "    \n",
    "out_center=wid.interactive_output(morpho, {'iterate':morpho_iter_s})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THRESHOLDING\n",
    "\n",
    "### Simple Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ret,thresh = cv2.threshold(img_gray,simple_thresh_slider.value,255,cv2.THRESH_BINARY)\n",
    "def simple_thresh(value, img=img):\n",
    "    if simple_thresh_drop.value == 'THRESH_BINARY':\n",
    "        ret,thresh = cv2.threshold(img,value,255,cv2.THRESH_BINARY)\n",
    "    elif simple_thresh_drop.value == 'THRESH_BINARY_INV':\n",
    "        ret,thresh = cv2.threshold(img,value,255,cv2.THRESH_BINARY_INV)\n",
    "    elif simple_thresh_drop.value == 'THRESH_TRUNC':\n",
    "        ret,thresh = cv2.threshold(img,value,255,cv2.THRESH_TRUNC)\n",
    "    elif simple_thresh_drop.value == 'THRESH_TOZERO':\n",
    "        ret,thresh = cv2.threshold(img,value,255,cv2.THRESH_TOZERO)\n",
    "    elif simple_thresh_drop.value == 'THRESH_TOZERO_INV':\n",
    "        ret,thresh = cv2.threshold(img,value,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(thresh, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([thresh],[0],None,[256],[0,256])\n",
    "        \n",
    "out_center=wid.interactive_output(simple_thresh, {'value':simple_thresh_slider})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adapta_thresh(block_size, C, img=img_gray):\n",
    "    ret,thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "    if adapta_thresh_drop.value == 'ADAPTIVE_THRESH_MEAN_C':\n",
    "        thresh = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,block_size,C)\n",
    "        \n",
    "    elif simple_thresh_drop.value == 'ADAPTIVE_THRESH_GAUSSIAN_C':\n",
    "        thresh = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,block_size,C)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(thresh, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([thresh],[0],None,[256],[0,256])\n",
    "    \n",
    "out_center=wid.interactive_output(adapta_thresh, {'block_size':adapta_block_size,\n",
    "                                                 'C':adapta_block_C})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarização de Otsu's (Verificar)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#img = cv2.imread('/root/MEGA/Códigos/cvgran/imagens/desmonte.jpg', 0)\n",
    "ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "img = cv2.imread('/root/MEGA/Códigos/cvgran/imagens/desmonte.jpg', 0)\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "# find normalized_histogram, and its cumulative distribution function\n",
    "hist = cv2.calcHist([blur],[0],None,[256],[0,256])\n",
    "hist_norm = hist.ravel()/hist.max()\n",
    "Q = hist_norm.cumsum()\n",
    "\n",
    "bins = np.arange(256)\n",
    "\n",
    "fn_min = np.inf\n",
    "thresh = -1\n",
    "\n",
    "for i in range(1,256):\n",
    "    p1,p2 = np.hsplit(hist_norm,[i]) # probabilities\n",
    "    q1,q2 = Q[i],Q[255]-Q[i] # cum sum of classes\n",
    "    b1,b2 = np.hsplit(bins,[i]) # weights\n",
    "\n",
    "# find otsu's threshold value with OpenCV function\n",
    "ret, otsu = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)\n",
    "plt.imshow(otsu)\n",
    "### Threshold com algoritmo WATERSHED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waresshed Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def water(op_iter, bg_iter, sf_tfactor, t_value, g_img=img_gray, img=img_rgb):\n",
    "    #water = cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(g_img,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = op_iter)\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=bg_iter)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,sf_tfactor*dist_transform.max(),t_value,0)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "    ###############################################################\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    # Add one to all labels so that sure background is not 0, but 1##################\n",
    "    markers = markers+1\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    ###############################################################\n",
    "    markers = cv2.watershed(img, markers)\n",
    "    img[markers == -1] = [255,0,0]\n",
    "    ###############################################################\n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(markers, 0, 0)\n",
    "        \n",
    "    #hist.y=cv2.calcHist([thresh],[0],None,[256],[0,256])\n",
    "\n",
    "out_center=wid.interactive_output(water, {'op_iter':ws_op_iter,\n",
    "                                         'bg_iter':ws_bg_iter,\n",
    "                                         'sf_tfactor':ws_sf_tfactor,\n",
    "                                         't_value':ws_sf_tvalue})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de Bordas (Operador Laplaciano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Operador Laplaciano\n",
    "def laplace(k_type, img=img_gray):\n",
    "    edge_img = cv2.Canny(img,t1,t2)\n",
    "\n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(edge_img, 0, 0)\n",
    "    \n",
    "    hist.y=cv2.calcHist([edge_img],[0],None,[256],[0,256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector de Extremidades Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "17"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def canny(t1, t2, img=img_gray):\n",
    "    edge_img = cv2.Canny(img,t1,t2)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(edge_img, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([edge_img],[0],None,[256],[0,256])\n",
    "    \n",
    "out_centercenter=wid.interactive_output(canny, {'t1':c_t1, 't2':c_t2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação de Imagens\n",
    "\n",
    "### Achando Contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "18"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contour(t_value, img=img_rgb):\n",
    "    retval, thresh = cv2.threshold(img_gray, t_value, 255, 0)\n",
    "    contours,hierarchy= cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contornada=cv2.drawContours(img.copy(), contours, -1, (0, 255, 0))\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(contornada, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([contornada],[0],None,[256],[0,256])\n",
    "\n",
    "out_center=wid.interactive_output(contour, {'t_value':contour_t_value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casco Convexo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    },
    "tags": []
   },
   "source": [
    "def hull(t_value, img=img_rgb):\n",
    "    retval, thresh = cv2.threshold(img_gray, t_value, 255, 0)\n",
    "    contours,hierarchy= cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = contours[0]\n",
    "    \n",
    "    hull = cv2.convexHull(cnt)\n",
    "    \n",
    "    hulled = cv2.drawContours(img.copy(), [hull], -1, (0, 255, 0), 1) \n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(hulled, 0, 0)\n",
    "        \n",
    "    hist.y=cv2.calcHist([thresh],[0],None,[256],[0,256])\n",
    "\n",
    "out_center=wid.interactive_output(hull, {'t_value':im_seg_h_t})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de Elipses (Verificar)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "20"
    },
    "tags": []
   },
   "source": [
    "def a_elipse(t_value, img=img_rgb):\n",
    "    etval, thresh = cv2.threshold(img_gray, t_value, 255, 0)\n",
    "    contours,hierarchy= cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = contours[0]\n",
    "    \n",
    "    ellipse = cv.fitEllipse(cnt)\n",
    "    #with_e = cv.ellipse(img.copy(),ellipse,(0,255,0),1)\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.clear()\n",
    "        canvas.put_image_data(with_e, 0, 0)\n",
    "    \n",
    "    \n",
    "out_center=wid.interactive_output(a_elipse, {'t_value':im_seg_e_t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cv2.contourArea(i) > 100:\n",
    " \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
